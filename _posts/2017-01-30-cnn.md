---
layout: default
title: Convolutional Neural Network Architecture
title-img: images/2017/cnn/cnn-title-image.jpeg
---

In this post, I will try to explain the architecture of the CNN.Let me start by why is there a need for CNN and why it is becoming so popular.

<!--more-->

<!--more-->

## Regular Neural Nets do not scale

Suppose we have a 200x200x3 size image(3 is the number of channels - R, G, B) and we input it to our first hidden layer in the regular neural nets.This would lead to a total of 200x200x3 = 120,000 weights.And that is just one layer.As we consider more number of layers, the parameters would add up quickly.Clearly, this full connectivity is wasteful and the huge number of parameters would quickly lead to overfitting.

{% include image.html img="images/2017/cnn/comparing-regular-and-cnn.jpeg" title="Regular Neural Net" caption=" A regular 3-layer Neural Network" %}

## 3D Volumes of Neurons

In particular, unlike a regular Neural Network, the layers of a ConvNet have neurons arranged in 3 dimensions: width, height, depth. (Note that the word depth here refers to the third dimension of an activation volume, not to the depth of a full Neural Network, which can refer to the total number of layers in a network.) For example, the input images in CIFAR-10 are an input volume of activations, and the volume has dimensions 32x32x3 (width, height, depth respectively). The neurons in a layer will only be connected to a small region of the layer before it, instead of all of the neurons in a fully-connected manner. This model is actually found in animal visual cortex.Individual cortical neurons respond to stimuli in a restricted region of space known as the receptive field. The receptive fields of different neurons partially overlap such that they tile the visual field. The response of an individual neuron to stimuli within its receptive field can be approximated mathematically by a convolution operation.

{% include image.html img="images/2017/cnn/comparing-regular-and-cnn2.jpeg" title="Convolutional Neural Net" caption="Every layer of a ConvNet transforms the 3D input volume to a 3D output volume of neuron activations. In this example, the red input layer holds the image, so its width and height would be the dimensions of the image, and the depth would be 3 (Red, Green, Blue channels)." %}

## What is a convolution?

Convolutions can be thought of as a sliding window function applied to a matrix.This sliding window is called as *filter*, *kernel* or *feature extractor*.

{% include image.html img="images/2017/cnn/kernel-convolution.jpg" title="Regular Neural Net" caption=" A regular 3-layer Neural Network" %}

# CNN Architecture:

Let's take each component one by one. 

## Input layer

Unlike regular neural nets where we have one-dimensional input vector, here we have 3D image as the input.The three dimensions are `height`, `width` and `channels` (3 if RGB image, 1 if grayscale.)

## Filter

A filter is a matrix of weights which slides over the input image and does dot product with the image matrix just below it simultaneously.It then passes the result through a ReLU or tanH activation neuron thus outputting single element of *activation map*.The dimensions of a filter depend on the input *thickness*. If the input image/layer has 3 channels/thickness, the filter dimension would be something like 5x5x3.

## Convolution layer

As we slide the filter over the input image, we get activations and all of them as a whole form one layer of activation maps.There is a simple math involved as to calculate the dimensions of output activation map depending on the the input and filter dimensions and quantity.

```
Output size = (N - F)/Stride + 1
where  N = input spatial dimension (eg. a 32x32x3 image would have N = 32),
F = filter dimension (eg. 3x3, 5x5, 11x11)

```

The depth of the activation map or number of layers in the output(slices of activation maps) depend on the number of filters we are using.

```
Activation map depth = Number of filters used.
```
But what are *strides* ? Strides are the number of steps to move while sliding over input.
There is one more thing left which is padding.Let's look at the significance of padding by an example.Suppose we have a 32x32 image and we are using a filter of size 5x5.Taking stride as 1, what will be the dimension of the output after one convolution?

```
(N-F)/S + 1 = (32-5)/1 + 1 = 28
```
Okay, now let's use this output as an input to out next convolution.The result will be `24`. So we see that the output shrinks gradually at the beginning.This was just an example.In real life scenario, it shrinks even faster.Padding helps us avoid this situation by keeping the output dimension either same or more.It is a process in which the input is padded with `0's` on height and width sides.For an example,in the following image, a 7x7 image has been padded with 1 pixel border.What is the corresponding output dimension?

{% include image.html img="images/2017/cnn/padding.png" title="Padding" caption="Padding helps maintain the output dimension(spatially)" %}

```
N = 9, F = 3, S = 1
(N-F)/S + 1 = (9-3)/1 + 1 = 7
```
That's same as the input! Thus we see that we can control the shrinking of our output by padding.We can also modify about formula to add padding.

```
(N − F + 2P)/S + 1

where P is padding(0,1,2,3...)

```
REFERENCES:
[1]Hubel, D. and Wiesel, T. (1968). Receptive fields and functional architecture of monkey striate cortex. Journal of Physiology (London), 195, 215–243.
